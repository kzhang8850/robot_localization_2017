# CompRobo - Robo Localization - Writeup

**Particle Filter Demo**

![Particle Filter Demo](https://github.com/kzhang8850/robot_localization_2017/blob/master/my_localizer/particle_filter_demo.gif "Particle Filter Demo")

**What was the goal of your project?**

The goal of the project was to create a probabilistic system that would allow for a robot Neato to determine where in space it is in relation to the confinements of a known room or group of known walls. In other words, the goal is to help the Neato answer the question "Where am I?" inside of a mapped environment.

**How did you solve the problem? (Note: this doesn't have to be super-detailed, you should try to explain what you did at a high-level so that others in the class could reasonably understand what you did).**

To solve the problem of where the Neato is, our team used a particle filter system. The idea is that given an arbitrary cloud of vector guesses, or particles, as to where the Neato is based on an initial estimate, each iteration the particle cloud will update its position for each particle based on how the Neato moved. Then the particles will be re-weighted based on their accuracy towards aligning with the actual measurements given by the Neato's laser scan. The particles are resampled with new particles having a higher probability of being drawn onto the  higher weighted particles of the previous particle cloud, until all the particles are aligned with the position of where the Neato "really" is.

Initializing the particle cloud is simple randomization around a chosen initial guess. Updating the particle cloud to reflect the movements of the Neato involved using trigonometry to calculate the movements of the particle given its different heading and coordinate frame from the actual Neato and the odom frame. We also added noise into the updates to add some variability into the updates to make sure that we hit as many possible robot locations as we reasonably could. The re-weighting took the form of calculating the error between each particle's "measurements" and the laser scan measurements of the Neato, and then creating a probability distribution that favored more accurate particles. Finally, resampling the particles utilized a re-sampler which drew a new sample of the same size from the previous particle cloud but using the new updated weights of each particle as the probability distribution. This cycle repeats as long as the Neato is alive, and eventually all particles should converge onto the Neato's location.

**Describe a design decision you had to make when working on your project and what you ultimately did (and why)? These design decisions could be particular choices for how you implemented some part of an algorithm or perhaps a decision regarding which of two external packages to use in your project.**

One decision we made while making our particle filter was how we would calculate a particle's weight given the characteristics of its error from the actual robot's location. We decided to take 36 unique error measurements for each particle, sum all the error, raise the error to some power, invert that value, and then normalize all particle weights to add to 1. Once we had decided on this method of weight calculation, we were able to fine-tune the system by changing the exponent that we raised the error sum to before inverting. The higher the exponent, the higher the weight for more accurate (less erroneous) particles, and the more likely it was for these more accurate particles to be chosen during the resampling process. However, higher exponents increase the likelihood that a low-error, but ultimately incorrect mode could be chosen as the estimated location of the robot. After playing with the exponent for a bit and ranging from 1-10, we decided on a power of 5 to provide the appropriate weight to particles. 

Another design decision that we made was to choose, when already given a particle cloud with fully defined weights, how to estimate the robot's position. We initially placed the robot on the particle with the highest weight, but found that the robot jumped around too much and the most highly weighted particle (especially at the beginning of the particle filter process) was not always a good estimate of where the robot was. Our final position estimation system essentially found the center of mass of the particle cloud where each particle's weight was equivalent to its mass. This smoothed out the position estimation much more and caused the robot to be placed more closely to large groupings of particles.

**What if any challenges did you face along the way?**

Throughout this project we had trouble verifying the functionality our incrementally developed features. For example, when writing code for how to reassign weights to each particle, we had a hard time checking that we assigned weights correctly. We ended up writing the resampling code before testing the reweighting code and then checking everything all at once. Something about our system obviously wasn't working, but we were unable to isolate the problem to any single area of the program (it ended up being a degrees to radians conversion in our reweighting code).

Another challenge we faced was dealing with edge cases or drift. There was a time in our project development where we actually managed to fully complete the particle filter, and upon testing it found that initially it worked fine. However, we discovered that over time the particle cloud would drift away from the boundaries of the actual map, and the model of the robot would in some configurations not work as intended, as if the update particles method was not working correctly. We eventually noticed that some of our trigonometry was incorrect (arctan vs arctan2), which helped enormously, but our particle filter still becomes slowly offset from the true position of the robot up to about .2 meters.

**What would you do to improve your project if you had more time?**

One thing we would consider if we had more time is investigating different ways to generate a probability distribution from the errors found in the particles to make it such that the particles with very little error are much higher favored than the particles with large errors. The current iteration of our particle filter uses a probability generator that doesn't really differentiate the two kinds of particles as strongly as we would like. It was empirically proven that the current method of creating the probability distribution would make it possible that a particle with large error could be chosen as the particle of choice simply due to chance. Looking into this problem would make our particle filter much more robust and accurate.

Another idea that could be improved upon is creating a more robust way to update the particles in the particle cloud for every move by the Neato. The codebase showed a #TODO for sample_motion_odometry. Our current way of updating the particles involves a lot of trigonometry to convert between reference frames. We're not sure entirely what sample_motion_odometry is, but it would something interesting to look into, especially since our update method is primitive and looks at the extremely simple breakdown of r1, d, and r2 to figure out where the particle should be based on how the Neato moved.

A final idea of improvement might be to consider a completely different approach to the problem of "Where am I?" and try to find better solutions other than a particle filter, which is more of a probabilitistic method to the problem that more approximates the position of the Neato than actually finds it. The codebase also had a #TODO method that mentioned a ray tracing likelihood model, which we also have no idea about. But it would be interesting had we more time to look into what other approaches there are to localize a robot and contemplate the pros and cons between them.

**Did you learn any interesting lessons for future robotic programming projects? These could relate to working on robotics projects in teams, working on more open-ended (and longer term) problems, or any other relevant topic.**

An interesting lesson that we learned (that can be applied to any project) is that breaking a large and seemingly impossible problem into small and realistic pieces allows a project to make reasonable and consistent progress where there would otherwise be an absence of progress. Being able to work within a thoughtfully laid out architecture for a particle filter made this project much less daunting and much more digestible. A very reasonable workflow for future projects could be to create a similarly designed software skeleton and proceed through the project by implementing the code within each fragment until the project's completion.
